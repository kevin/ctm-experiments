{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15cbaf3",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ca5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.ctm' from '/home/kevin/projects/ctm-experiments/experiments/../models/ctm.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax import nnx\n",
    "import flax\n",
    "import evojax\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from models.ctm import CTM\n",
    "\n",
    "# dynamic reload\n",
    "import importlib\n",
    "importlib.reload(sys.modules[\"models.ctm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417a762",
   "metadata": {},
   "source": [
    "create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2231639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original output: [ 0.01526764 -0.06009712 -0.00644524]\n",
      "Flattened parameter vector shape: (2286,)\n"
     ]
    }
   ],
   "source": [
    "def flatten_params(model):\n",
    "    \"\"\"Extract parameters as a single flattened vector.\"\"\"\n",
    "    # Get the model state, filtering for parameters only\n",
    "    state = nnx.state(model, nnx.Param)\n",
    "    \n",
    "    # Flatten the parameter state\n",
    "    flat_params, tree_def = jax.tree_util.tree_flatten(state)\n",
    "    param_shapes = [p.shape for p in flat_params]\n",
    "    \n",
    "    # Pre-compute split indices as concrete values\n",
    "    param_sizes = [int(np.prod(shape)) for shape in param_shapes]\n",
    "    split_indices = [int(idx) for idx in np.cumsum(param_sizes[:-1])]\n",
    "    \n",
    "    flattened_vector = jnp.concatenate([p.flatten() for p in flat_params])\n",
    "    return flattened_vector, (tree_def, param_shapes, split_indices)\n",
    "\n",
    "\n",
    "def unflatten_and_set_params(model, flattened_vector, restore_info):\n",
    "    \"\"\"Restore parameters from a flattened vector and update the model.\"\"\"\n",
    "    tree_def, shapes, split_indices = restore_info\n",
    "    \n",
    "    # Use the pre-computed concrete split indices\n",
    "    param_arrays = jnp.split(flattened_vector, split_indices)\n",
    "    \n",
    "    # Reshape each array back to its original shape\n",
    "    reshaped_params = [arr.reshape(shape) for arr, shape in zip(param_arrays, shapes)]\n",
    "    \n",
    "    # Reconstruct the parameter tree\n",
    "    new_param_state = jax.tree_util.tree_unflatten(tree_def, reshaped_params)\n",
    "    \n",
    "    # Update the model with new parameters\n",
    "    nnx.update(model, new_param_state)\n",
    "\n",
    "# Test the functions\n",
    "config = {\n",
    "    \"iterations\": 5,\n",
    "    \"d_model\": 6,\n",
    "    \"d_input\": 12,\n",
    "    \"memory_length\": 5,\n",
    "    \"memory_hidden_dims\": 6,\n",
    "    \"heads\": 1,\n",
    "    \"n_synch_out\": 6,\n",
    "    \"n_synch_action\": 6,\n",
    "    \"out_dims\": 3,\n",
    "}\n",
    "\n",
    "ctm = CTM(config, nnx.Rngs(0))\n",
    "\n",
    "# Get original output\n",
    "original_output = ctm(jnp.zeros((1, 12)))\n",
    "print(\"Original output:\", original_output)\n",
    "\n",
    "# Flatten parameters\n",
    "flattened_params, restore_info = flatten_params(ctm)\n",
    "print(f\"Flattened parameter vector shape: {flattened_params.shape}\")\n",
    "\n",
    "# # Modify parameters (add noise)\n",
    "# modified_params = flattened_params + 0.1 * jax.random.normal(jax.random.PRNGKey(42), flattened_params.shape)\n",
    "\n",
    "# # Set modified parameters\n",
    "# unflatten_and_set_params(ctm, modified_params, restore_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3781f8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EvoJAX: 2025-07-29 18:29:15,194 [INFO] Testing CTM\n",
      "EvoJAX: 2025-07-29 18:29:15,195 [INFO] Jax backend: [CudaDevice(id=0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.devices():\n",
      "NVIDIA GeForce RTX 3060 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "from brax import envs\n",
    "from brax.io import html\n",
    "\n",
    "from evojax import SimManager\n",
    "from evojax import ObsNormalizer\n",
    "from evojax.algo import PGPE\n",
    "from evojax.policy import MLPPolicy\n",
    "from evojax.policy.base import PolicyState\n",
    "from evojax.policy.base import PolicyNetwork\n",
    "from evojax.task.cartpole import CartPoleSwingUp\n",
    "from evojax.task.slimevolley import SlimeVolley\n",
    "from evojax.util import create_logger\n",
    "from evojax import Trainer\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "print('jax.devices():')\n",
    "jax.devices()\n",
    "\n",
    "# Let's create a directory to save logs and models.\n",
    "log_dir = '../logs'\n",
    "logger = create_logger(name='EvoJAX', log_dir=log_dir)\n",
    "logger.info('Testing CTM')\n",
    "\n",
    "logger.info('Jax backend: {}'.format(jax.local_devices()))\n",
    "!nvidia-smi --query-gpu=name --format=csv,noheader\n",
    "\n",
    "class CTMPolicy(PolicyNetwork):\n",
    "    def __init__(self, input_dim, output_dim, rngs=nnx.Rngs(0)):\n",
    "        self.ctm = CTM({\n",
    "            \"iterations\": 5,\n",
    "            \"d_model\": 6,\n",
    "            \"d_input\": input_dim,\n",
    "            \"memory_length\": 5,\n",
    "            \"memory_hidden_dims\": 6,\n",
    "            \"heads\": 1,\n",
    "            \"n_synch_out\": 6,\n",
    "            \"n_synch_action\": 6,\n",
    "            \"out_dims\": output_dim,\n",
    "            }, rngs)\n",
    "        params, restore_info = flatten_params(self.ctm)\n",
    "        self.restore_info = restore_info\n",
    "        self.num_params = params.shape[0]\n",
    "\n",
    "    @partial(nnx.jit, static_argnums=(0,))\n",
    "    def get_actions(self, t_states, params, p_states):\n",
    "        def get_action_single(single_params, single_obs):\n",
    "            # unflatten_and_set_params(self.ctm, single_params, self.restore_info)\n",
    "            # return self.ctm(single_obs)\n",
    "            tmp_ctm = CTM(self.ctm.config, rngs=nnx.Rngs(0))\n",
    "            unflatten_and_set_params(tmp_ctm, single_params, self.restore_info)\n",
    "            return tmp_ctm(jnp.expand_dims(single_obs, 0))\n",
    "        \n",
    "        # vmap over parameter vectors\n",
    "        actions = jax.vmap(get_action_single)(params, t_states.obs)\n",
    "        return actions, p_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca0c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EvoJAX: 2025-07-29 18:46:09,009 [INFO] use_for_loop=False\n",
      "EvoJAX: 2025-07-29 18:46:09,023 [INFO] Start to train for 1000 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(3,)\n",
      "2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EvoJAX: 2025-07-29 18:46:44,057 [INFO] Iter=20, size=64, max=-29.1875, avg=-30.8125, min=-32.5000, std=0.6693\n",
      "EvoJAX: 2025-07-29 18:47:14,027 [INFO] Iter=40, size=64, max=-28.2500, avg=-28.7754, min=-31.8125, std=0.4284\n",
      "EvoJAX: 2025-07-29 18:47:43,913 [INFO] Iter=60, size=64, max=-29.8750, avg=-30.2373, min=-30.6875, std=0.1680\n",
      "EvoJAX: 2025-07-29 18:48:14,079 [INFO] Iter=80, size=64, max=-28.0625, avg=-30.2539, min=-31.4375, std=0.7106\n",
      "EvoJAX: 2025-07-29 18:48:43,914 [INFO] Iter=100, size=64, max=-29.1875, avg=-31.4014, min=-37.0000, std=1.3234\n",
      "EvoJAX: 2025-07-29 18:49:14,069 [INFO] Iter=120, size=64, max=-29.1250, avg=-31.0479, min=-32.9375, std=0.7745\n",
      "EvoJAX: 2025-07-29 18:49:43,743 [INFO] Iter=140, size=64, max=-28.3125, avg=-30.4473, min=-32.1875, std=0.6823\n",
      "EvoJAX: 2025-07-29 18:50:13,685 [INFO] Iter=160, size=64, max=-27.9375, avg=-30.6592, min=-32.7500, std=0.9414\n",
      "EvoJAX: 2025-07-29 18:50:43,618 [INFO] Iter=180, size=64, max=-28.3750, avg=-29.7471, min=-32.0000, std=0.7245\n",
      "EvoJAX: 2025-07-29 18:51:13,379 [INFO] Iter=200, size=64, max=-27.0000, avg=-28.7510, min=-32.0625, std=0.8797\n",
      "EvoJAX: 2025-07-29 18:51:17,955 [INFO] [TEST] Iter=200, #tests=128, max=-3.0000, avg=-4.8203, min=-5.0000, std=0.4408\n",
      "EvoJAX: 2025-07-29 18:51:48,055 [INFO] Iter=220, size=64, max=-26.6875, avg=-28.5000, min=-30.5000, std=0.9157\n",
      "EvoJAX: 2025-07-29 18:52:17,847 [INFO] Iter=240, size=64, max=-24.3750, avg=-26.6689, min=-29.2500, std=0.9129\n",
      "EvoJAX: 2025-07-29 18:52:47,992 [INFO] Iter=260, size=64, max=-23.6875, avg=-26.7842, min=-29.8125, std=1.3294\n",
      "EvoJAX: 2025-07-29 18:53:17,936 [INFO] Iter=280, size=64, max=-23.1250, avg=-25.8584, min=-31.6875, std=1.2238\n",
      "EvoJAX: 2025-07-29 18:53:48,059 [INFO] Iter=300, size=64, max=-22.8125, avg=-24.8955, min=-32.6875, std=1.4542\n",
      "EvoJAX: 2025-07-29 18:54:18,159 [INFO] Iter=320, size=64, max=-21.5625, avg=-23.6035, min=-26.0000, std=0.9371\n",
      "EvoJAX: 2025-07-29 18:54:48,221 [INFO] Iter=340, size=64, max=-19.6250, avg=-22.0410, min=-25.0625, std=0.9510\n",
      "EvoJAX: 2025-07-29 18:55:18,226 [INFO] Iter=360, size=64, max=-18.4375, avg=-20.9941, min=-24.9375, std=1.3266\n",
      "EvoJAX: 2025-07-29 18:55:48,415 [INFO] Iter=380, size=64, max=-17.3750, avg=-19.3906, min=-22.7500, std=0.9364\n",
      "EvoJAX: 2025-07-29 18:56:18,369 [INFO] Iter=400, size=64, max=-15.2500, avg=-17.7051, min=-20.2500, std=1.1015\n",
      "EvoJAX: 2025-07-29 18:56:19,726 [INFO] [TEST] Iter=400, #tests=128, max=-3.0000, avg=-4.7734, min=-5.0000, std=0.5186\n",
      "EvoJAX: 2025-07-29 18:56:49,558 [INFO] Iter=420, size=64, max=-14.0625, avg=-15.6729, min=-18.4375, std=1.0218\n",
      "EvoJAX: 2025-07-29 18:57:19,474 [INFO] Iter=440, size=64, max=-10.7500, avg=-13.6582, min=-17.6875, std=1.4053\n",
      "EvoJAX: 2025-07-29 18:57:49,540 [INFO] Iter=460, size=64, max=-9.7500, avg=-12.4561, min=-18.5625, std=1.7551\n",
      "EvoJAX: 2025-07-29 18:58:19,408 [INFO] Iter=480, size=64, max=-7.6250, avg=-11.3301, min=-19.6875, std=2.5007\n",
      "EvoJAX: 2025-07-29 18:58:49,206 [INFO] Iter=500, size=64, max=-7.4375, avg=-9.9639, min=-16.8125, std=1.9496\n",
      "EvoJAX: 2025-07-29 18:59:19,143 [INFO] Iter=520, size=64, max=-7.0000, avg=-10.3965, min=-20.2500, std=2.6040\n",
      "EvoJAX: 2025-07-29 18:59:49,101 [INFO] Iter=540, size=64, max=-6.5000, avg=-10.2451, min=-16.6875, std=2.1784\n",
      "EvoJAX: 2025-07-29 19:00:18,770 [INFO] Iter=560, size=64, max=-6.3125, avg=-9.3574, min=-17.7500, std=2.6168\n",
      "EvoJAX: 2025-07-29 19:00:48,846 [INFO] Iter=580, size=64, max=-5.1875, avg=-8.1270, min=-17.6875, std=2.2226\n",
      "EvoJAX: 2025-07-29 19:01:18,879 [INFO] Iter=600, size=64, max=-5.2500, avg=-7.2529, min=-11.1250, std=1.3926\n",
      "EvoJAX: 2025-07-29 19:01:19,991 [INFO] [TEST] Iter=600, #tests=128, max=0.0000, avg=-4.0938, min=-5.0000, std=1.1821\n",
      "EvoJAX: 2025-07-29 19:01:49,752 [INFO] Iter=620, size=64, max=-4.5000, avg=-7.8848, min=-33.1875, std=4.0849\n",
      "EvoJAX: 2025-07-29 19:02:19,537 [INFO] Iter=640, size=64, max=-3.9375, avg=-7.2080, min=-11.5000, std=1.9302\n",
      "EvoJAX: 2025-07-29 19:02:49,327 [INFO] Iter=660, size=64, max=-3.5625, avg=-7.0898, min=-33.8125, std=4.8219\n",
      "EvoJAX: 2025-07-29 19:03:19,487 [INFO] Iter=680, size=64, max=-2.5625, avg=-5.7979, min=-13.6875, std=2.0225\n",
      "EvoJAX: 2025-07-29 19:03:49,334 [INFO] Iter=700, size=64, max=-2.2500, avg=-5.3115, min=-10.2500, std=1.6860\n",
      "EvoJAX: 2025-07-29 19:04:19,144 [INFO] Iter=720, size=64, max=-2.4375, avg=-4.7861, min=-12.4375, std=1.5682\n",
      "EvoJAX: 2025-07-29 19:04:49,069 [INFO] Iter=740, size=64, max=-2.8125, avg=-5.5469, min=-31.0625, std=3.7696\n",
      "EvoJAX: 2025-07-29 19:05:18,987 [INFO] Iter=760, size=64, max=-2.6250, avg=-4.6982, min=-35.0000, std=4.0470\n",
      "EvoJAX: 2025-07-29 19:05:48,973 [INFO] Iter=780, size=64, max=-2.0625, avg=-4.8652, min=-33.8125, std=5.2705\n",
      "EvoJAX: 2025-07-29 19:06:18,997 [INFO] Iter=800, size=64, max=-2.0000, avg=-3.4990, min=-7.3750, std=0.9859\n",
      "EvoJAX: 2025-07-29 19:06:20,249 [INFO] [TEST] Iter=800, #tests=128, max=2.0000, avg=-2.0078, min=-5.0000, std=1.6840\n",
      "EvoJAX: 2025-07-29 19:06:50,198 [INFO] Iter=820, size=64, max=-1.3750, avg=-2.9092, min=-6.1250, std=0.8503\n",
      "EvoJAX: 2025-07-29 19:07:20,059 [INFO] Iter=840, size=64, max=-1.1250, avg=-3.8838, min=-36.3750, std=4.3722\n",
      "EvoJAX: 2025-07-29 19:07:50,078 [INFO] Iter=860, size=64, max=-0.8125, avg=-2.5430, min=-6.3750, std=1.1073\n",
      "EvoJAX: 2025-07-29 19:08:20,010 [INFO] Iter=880, size=64, max=-0.9375, avg=-3.1074, min=-30.8125, std=3.7100\n",
      "EvoJAX: 2025-07-29 19:08:50,089 [INFO] Iter=900, size=64, max=-0.8750, avg=-2.6064, min=-6.8750, std=1.3097\n",
      "EvoJAX: 2025-07-29 19:09:21,056 [INFO] Iter=920, size=64, max=-0.7500, avg=-2.1289, min=-5.6875, std=1.0663\n",
      "EvoJAX: 2025-07-29 19:09:52,349 [INFO] Iter=940, size=64, max=-0.7500, avg=-2.1367, min=-6.1250, std=1.1822\n",
      "EvoJAX: 2025-07-29 19:10:22,791 [INFO] Iter=960, size=64, max=-0.2500, avg=-3.1436, min=-32.6875, std=5.6271\n",
      "EvoJAX: 2025-07-29 19:10:52,875 [INFO] Iter=980, size=64, max=-0.6875, avg=-3.3457, min=-29.1875, std=5.4918\n",
      "EvoJAX: 2025-07-29 19:11:23,130 [INFO] [TEST] Iter=1000, #tests=128, max=3.0000, avg=-0.7266, min=-5.0000, std=1.4881\n",
      "EvoJAX: 2025-07-29 19:11:23,133 [INFO] Training done, best_score=-0.7266\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "train_task = SlimeVolley(test=False, max_steps=3000)\n",
    "test_task = SlimeVolley(test=True, max_steps=3000)\n",
    "\n",
    "# # We use a feedforward network as our policy.\n",
    "# # By default, MLPPolicy uses \"tanh\" as its activation function for the output.\n",
    "# policy = MLPPolicy(\n",
    "#     input_dim=train_task.obs_shape[0],\n",
    "#     hidden_dims=[64, 64],\n",
    "#     output_dim=train_task.act_shape[0],\n",
    "#     logger=logger,\n",
    "# )\n",
    "\n",
    "policy = CTMPolicy(train_task.obs_shape[0], train_task.act_shape[0], nnx.Rngs(0))\n",
    "\n",
    "print(train_task.obs_shape)\n",
    "print(train_task.act_shape)\n",
    "\n",
    "print(policy.num_params)\n",
    "\n",
    "# We use PGPE as our evolution algorithm.\n",
    "# If you want to know more about the algorithm, please take a look at the paper:\n",
    "# https://people.idsia.ch/~juergen/nn2010.pdf \n",
    "lr = 1.0\n",
    "center_learning_rate = 0.15 * lr\n",
    "stdev_learning_rate = 0.1 * lr\n",
    "init_stdev = 0.1 * lr\n",
    "\n",
    "solver = PGPE(\n",
    "    pop_size=64,\n",
    "    param_size=policy.num_params,\n",
    "    optimizer='adam',\n",
    "    # center_learning_rate=0.15, # careful, needs to scale with repeats or pop size. originally .05 \n",
    "    center_learning_rate=center_learning_rate,\n",
    "    stdev_learning_rate=stdev_learning_rate,\n",
    "    init_stdev=init_stdev,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "train_scores = []\n",
    "train_x = []\n",
    "test_scores = []\n",
    "test_x = []\n",
    "\n",
    "def log_scores(current_iter, scores, stage):\n",
    "    if stage == \"train\":\n",
    "        train_scores.append(scores.mean())\n",
    "        train_x.append(current_iter)\n",
    "    else:\n",
    "        test_scores.append(scores.mean())\n",
    "        test_x.append(current_iter)\n",
    "\n",
    "# Now that we have all the three components instantiated, we can create a\n",
    "# trainer and start the training process.\n",
    "trainer = Trainer(\n",
    "    policy=policy,\n",
    "    solver=solver,\n",
    "    train_task=train_task,\n",
    "    test_task=test_task,\n",
    "    max_iter=1000,\n",
    "    log_interval=20,\n",
    "    test_interval=200,\n",
    "    n_repeats=16, # duplicates\n",
    "    n_evaluations=128, #128,\n",
    "    seed=seed,\n",
    "    log_dir=log_dir,\n",
    "    logger=logger,\n",
    "    log_scores_fn=log_scores,\n",
    ")\n",
    "\n",
    "_ = trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7667c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Training Graph⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "                      \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "                  \u001b[38;5;8m  0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m\u001b[38;5;111m⡀\u001b[0m⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;111mtrain\u001b[0m\n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m⠀\u001b[38;5;111m⡀\u001b[0m\u001b[38;5;111m⡔\u001b[0m\u001b[38;5;111m⠈\u001b[0m\u001b[38;5;111m⠄\u001b[0m\u001b[38;5;111m⠁\u001b[0m\u001b[38;5;111m⠊\u001b[0m⠀⠀\u001b[38;5;111m⠒\u001b[0m⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m⠀\u001b[38;5;111m⢀\u001b[0m\u001b[38;5;111m⠄\u001b[0m\u001b[38;5;111m⠊\u001b[0m⠀\u001b[38;5;111m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⣀\u001b[0m\u001b[38;5;111m⢀\u001b[0m\u001b[38;5;111m⠄\u001b[0m\u001b[38;5;111m⠁\u001b[0m\u001b[38;5;111m⠈\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⠄\u001b[0m\u001b[38;5;111m⠊\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m\u001b[38;5;111m⠌\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m\u001b[38;5;111m⠆\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "   \u001b[38;5;15mAverage Score\u001b[0m      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⡠\u001b[0m\u001b[38;5;111m⠂\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m\u001b[38;5;111m⠔\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⢀\u001b[0m⠀\u001b[38;5;111m⠄\u001b[0m\u001b[38;5;111m⠂\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;111m⢠\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;111m⠤\u001b[0m\u001b[38;5;111m⠂\u001b[0m\u001b[38;5;111m⠈\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;111m⠃\u001b[0m\u001b[38;5;111m⠑\u001b[0m\u001b[38;5;111m⠂\u001b[0m\u001b[38;5;111m⠤\u001b[0m\u001b[38;5;111m⠐\u001b[0m\u001b[38;5;111m⠐\u001b[0m\u001b[38;5;111m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                  \u001b[38;5;8m-40\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \n",
      "                      \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "                      ⠀\u001b[38;5;8m0\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m1 000\u001b[0m⠀ \n",
      "                      ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;15mTraining Iteration\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    }
   ],
   "source": [
    "from uniplot import lineplot, lineplot_, scatterplot, scatterplot_\n",
    "from uniplot.canvas import *\n",
    "\n",
    "score = lineplot(train_x, train_scores, title=\"Training Graph\", xlabel=\"Training Iteration\", ylabel=\"Average Score\", color=\"#6699ff\",name=\"train\")\n",
    "print(score)\n",
    "# score2 = lineplot(test_x, test_scores, title=\"Testing Graph\", xlabel=\"Training Iteration\", ylabel=\"Average Score\", color=\"#ff6666\",name=\"test\")\n",
    "# print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1df257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imageio_ffmpeg: 2025-07-29 19:12:23,456 [WARNING] IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (336, 168) to (336, 176) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward=[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../logs/slimevolley.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's visualize the learned policy.\n",
    "\n",
    "def render(task, algo, policy):\n",
    "    \"\"\"Render the learned policy.\"\"\"\n",
    "\n",
    "    task_reset_fn = jax.jit(test_task.reset)\n",
    "    policy_reset_fn = jax.jit(policy.reset)\n",
    "    step_fn = jax.jit(test_task.step)\n",
    "    act_fn = jax.jit(policy.get_actions)\n",
    "\n",
    "    params = algo.best_params[None, :]\n",
    "    task_s = task_reset_fn(jax.random.PRNGKey(seed=seed)[None, :])\n",
    "    policy_s = policy_reset_fn(task_s)\n",
    "\n",
    "    single_task_s = jax.tree.map(lambda x: x[0], task_s)\n",
    "\n",
    "    # images = [CartPoleSwingUp.render(task_s, 0)]\n",
    "    images = [SlimeVolley.render(single_task_s, 0)]\n",
    "    done = False\n",
    "    step = 0\n",
    "    reward = 0\n",
    "    while not done:\n",
    "        act, policy_s = act_fn(task_s, params, policy_s)\n",
    "        task_s, r, d = step_fn(task_s, act)\n",
    "        step += 1\n",
    "        reward = reward + r\n",
    "        done = bool(d[0])\n",
    "        if step % 5 == 0:\n",
    "            # images.append(CartPoleSwingUp.render(task_s, 0))\n",
    "            single_task_s = jax.tree.map(lambda x: x[0], task_s)\n",
    "            images.append(SlimeVolley.render(single_task_s, 0))\n",
    "    print('reward={}'.format(reward))\n",
    "    return images\n",
    "\n",
    "\n",
    "imgs = render(test_task, solver, policy)\n",
    "# gif_file = os.path.join(log_dir, 'slimevolley.gif')\n",
    "# imgs[0].save(\n",
    "#     gif_file, save_all=True, append_images=imgs[1:], duration=40, loop=0)\n",
    "# Image(open(gif_file,'rb').read())\n",
    "\n",
    "# display mp4\n",
    "import imageio\n",
    "mp4_file = os.path.join(log_dir, 'slimevolley.mp4')\n",
    "imageio.mimsave(mp4_file, imgs, fps=24)\n",
    "from IPython.display import Video\n",
    "Video(mp4_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
